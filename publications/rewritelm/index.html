<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting - Liangchen Luo</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting" />
<meta property="og:description" content="Abstract Large Language Models (LLMs) have demonstrated impressive capabilities in creative tasks such as storytelling and E-mail generation. However, as LLMs are primarily trained on final text results rather than intermediate revisions, it might be challenging for them to perform text rewriting tasks. Most studies in the rewriting tasks focus on a particular transformation type within the boundaries of single sentences. In this work, we develop new strategies for instruction tuning and reinforcement learning to better align LLMs for cross-sentence rewriting tasks using diverse wording and structures expressed through natural languages including 1) generating rewriting instruction data from Wiki edits and public corpus through instruction generation and chain-of-thought prompting; 2) collecting comparison data for reward model training through a new ranking function." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.luolc.com/publications/rewritelm/" /><meta property="article:section" content="publications" />
<meta property="article:published_time" content="2024-03-24T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-03-24T00:00:00+00:00" />


		<meta itemprop="name" content="RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting">
<meta itemprop="description" content="Abstract Large Language Models (LLMs) have demonstrated impressive capabilities in creative tasks such as storytelling and E-mail generation. However, as LLMs are primarily trained on final text results rather than intermediate revisions, it might be challenging for them to perform text rewriting tasks. Most studies in the rewriting tasks focus on a particular transformation type within the boundaries of single sentences. In this work, we develop new strategies for instruction tuning and reinforcement learning to better align LLMs for cross-sentence rewriting tasks using diverse wording and structures expressed through natural languages including 1) generating rewriting instruction data from Wiki edits and public corpus through instruction generation and chain-of-thought prompting; 2) collecting comparison data for reward model training through a new ranking function."><meta itemprop="datePublished" content="2024-03-24T00:00:00+00:00" />
<meta itemprop="dateModified" content="2024-03-24T00:00:00+00:00" />
<meta itemprop="wordCount" content="164">
<meta itemprop="keywords" content="" />
		<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting"/>
<meta name="twitter:description" content="Abstract Large Language Models (LLMs) have demonstrated impressive capabilities in creative tasks such as storytelling and E-mail generation. However, as LLMs are primarily trained on final text results rather than intermediate revisions, it might be challenging for them to perform text rewriting tasks. Most studies in the rewriting tasks focus on a particular transformation type within the boundaries of single sentences. In this work, we develop new strategies for instruction tuning and reinforcement learning to better align LLMs for cross-sentence rewriting tasks using diverse wording and structures expressed through natural languages including 1) generating rewriting instruction data from Wiki edits and public corpus through instruction generation and chain-of-thought prompting; 2) collecting comparison data for reward model training through a new ranking function."/>

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">

	<link rel="shortcut icon" sizes="16x16 24x24 32x32 48x48 64x64" href="/favicon.ico">
		
		
<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-97612757-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [ ['$','$'], ["\\(","\\)"] ],
				processEscapes: true
			}
		});
	</script>
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="Liangchen Luo" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">Liangchen Luo</div>
					<div class="logo__tagline">A fool living in the amazing world</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			
			<a class="menu__link" href="/assets/other/CV-LiangchenLuo.pdf">
				
				<span class="menu__text">Curriculum Vitae</span>
				
			</a>
		</li>
		<li class="menu__item menu__item--active">
			
			<a class="menu__link" href="/publications/">
				
				<span class="menu__text">Publications</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting</h1>
			
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 577.545 577.545">
		<g>
			<path d="M245.531,245.532c4.893-4.896,11.42-7.589,18.375-7.589s13.482,2.696,18.375,7.589l49.734,49.734    c1.723,1.72,4.058,2.689,6.49,2.689s4.771-0.967,6.49-2.689l49.733-49.734c1.724-1.72,2.69-4.058,2.69-6.49    c0-2.433-0.967-4.771-2.69-6.49l-49.733-49.734c-21.668-21.662-50.469-33.589-81.093-33.589s-59.425,11.928-81.093,33.586    L33.602,332.022C11.934,353.69,0,382.494,0,413.128c0,30.637,11.934,59.432,33.605,81.084l49.731,49.73    c21.65,21.668,50.447,33.603,81.081,33.603s59.438-11.935,81.108-33.603l84.083-84.082c2.705-2.705,3.448-6.803,1.869-10.285    c-1.496-3.295-4.776-5.386-8.356-5.386c-0.205,0-0.407,0.007-0.615,0.021c-2.959,0.199-5.958,0.297-8.917,0.297    c-23.354,0-46.322-6.208-66.417-17.956c-1.444-0.844-3.042-1.254-4.629-1.254c-2.375,0-4.725,0.921-6.494,2.689l-53.238,53.238    c-4.902,4.901-11.426,7.604-18.372,7.604c-6.949,0-13.479-2.699-18.381-7.604l-49.734-49.734    c-4.908-4.896-7.61-11.411-7.616-18.348c-0.003-6.953,2.699-13.489,7.616-18.406L245.531,245.532z"/>
			<path d="M543.942,83.324L494.208,33.59C472.556,11.931,443.762,0,413.128,0s-59.438,11.928-81.105,33.587l-84.086,84.119    c-2.705,2.705-3.448,6.806-1.867,10.288c1.497,3.292,4.777,5.382,8.354,5.382c0.205,0,0.413-0.006,0.621-0.021    c2.987-0.202,6.013-0.303,9-0.303c23.4,0,46.316,6.206,66.274,17.947c1.45,0.854,3.057,1.267,4.65,1.267    c2.375,0,4.725-0.921,6.494-2.689l53.274-53.274c4.893-4.896,11.42-7.589,18.375-7.589s13.482,2.696,18.375,7.589l49.734,49.734    c10.123,10.135,10.123,26.634-0.003,36.775L332.017,332.014c-4.894,4.905-11.408,7.604-18.348,7.604    c-6.956,0-13.495-2.702-18.415-7.61l-49.723-49.725c-1.723-1.72-4.057-2.69-6.49-2.69c-2.433,0-4.771,0.967-6.49,2.69    l-49.734,49.734c-3.586,3.586-3.586,9.397,0,12.983l49.734,49.734c21.668,21.668,50.469,33.602,81.093,33.602    c30.625,0,59.426-11.934,81.094-33.602l149.205-149.206c21.668-21.658,33.603-50.462,33.603-81.102S565.61,104.983,543.942,83.324    z"/>
		</g>
	</svg>
	<ul class="tags__list">
	<li class="tags__item"><a class="tags__link btn" href="https://arxiv.org/abs/2305.15685" rel="tag">arXiv</a></li>
	<li class="tags__item"><a class="tags__link btn" href="https://www.luolc.com/publications/rewritelm/#bibtex" rel="tag">bib</a></li>
	<li class="tags__item"><a class="tags__link btn" href="https://github.com/google-research/google-research/tree/master/rewritelm" rel="tag">code</a></li>
</ul>
</div>
			<div class="pub__meta">Lei Shu, <b>Liangchen Luo</b>, Yun Zhu, Yinxiao Liu, Simon Tong, Jindong Chen, Lei Meng.<br>In
<em>Proceedings of the 38th AAAI Conference on Artificial Intelligence</em>, Vancouver, Canada.
2024.
			</div>
		</header><div class="content post__content clearfix">
			<h2 id="abstract">Abstract</h2>
<p>Large Language Models (LLMs) have demonstrated impressive capabilities in creative tasks such as storytelling and E-mail generation.
However, as LLMs are primarily trained on final text results rather than intermediate revisions, it might be challenging for them to perform text rewriting tasks.
Most studies in the rewriting tasks focus on a particular transformation type within the boundaries of single sentences.
In this work, we develop new strategies for instruction tuning and reinforcement learning to better align LLMs for cross-sentence rewriting tasks using diverse wording and structures expressed through natural languages including 1) generating rewriting instruction data from Wiki edits and public corpus through instruction generation and chain-of-thought prompting; 2) collecting comparison data for reward model training through a new ranking function.
To facilitate this research, we introduce OpenRewriteEval, a novel benchmark covers a wide variety of rewriting types expressed through natural language instructions.
Our results show significant improvements over a variety of baselines.
The public repository is available on <a href="https://github.com/google-research/google-research/tree/master/rewritelm">GitHub under Google Research</a>.</p>

		</div>








<h2 id="bibtex">BibTex</h2>
<pre><code>@inproceedings{Shu2024RewriteLM,
  author = {Shu, Lei and Luo, Liangchen and Zhu, Yun and Liu, Yinxiao and Tong, Simon and Chen, Jindong and Meng, Lei},
  title = {RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting},
  booktitle = {Proceedings of the 38th AAAI Conference on Artificial Intelligence},
  month = {March},
  year = {2024},
  address = {Vancouver, Canada}
}
</code></pre>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/publications/sira/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SiRA: Sparse Mixture of Low Rank Adaptation</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/publications/omegaprm/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Improve Mathematical Reasoning in Language Models by Automated Process Supervision</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2015-2025 Liangchen Luo.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> based on <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>