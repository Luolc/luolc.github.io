<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Critique Ability of Large Language Models</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.60.0" />
	<meta property="og:title" content="Critique Ability of Large Language Models" />
<meta property="og:description" content="Abstract Critical thinking is essential for rational decision-making and problem-solving. This skill hinges on the ability to provide precise and reasoned critiques and is a hallmark of human intelligence. In the era of large language models (LLMs), this study explores the ability of LLMs to deliver accurate critiques across various tasks. We are interested in this topic as a capable critic model could not only serve as a reliable evaluator, but also as a source of supervised signals for model tuning." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.luolc.com/publications/criticbench/" />
<meta property="article:published_time" content="2023-10-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-10-07T00:00:00+00:00" />

	<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Critique Ability of Large Language Models"/>
<meta name="twitter:description" content="Abstract Critical thinking is essential for rational decision-making and problem-solving. This skill hinges on the ability to provide precise and reasoned critiques and is a hallmark of human intelligence. In the era of large language models (LLMs), this study explores the ability of LLMs to deliver accurate critiques across various tasks. We are interested in this topic as a capable critic model could not only serve as a reliable evaluator, but also as a source of supervised signals for model tuning."/>

	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="shortcut icon" sizes="16x16 24x24 32x32 48x48 64x64" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-97612757-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			tex2jax: {
				inlineMath: [ ['$','$'], ["\\(","\\)"] ],
				processEscapes: true
			}
		});
	</script>
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo" role="banner">
			<a class="logo__link" href="/" title="Liangchen Luo" rel="home">
				<div class="logo__title">Liangchen Luo</div>
				<div class="logo__tagline">A fool living in the amazing world</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			
			<a class="menu__link" href="/assets/other/CV.pdf">Curriculum Vitae</a>
		</li>
		<li class="menu__item">
			
			<a class="menu__link" href="/publications/">Publications</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<section class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Critique Ability of Large Language Models</h1>
			
<div class="post__tags tags clearfix">
	<svg class="icon icon-tag" width="16" height="16" viewBox="0 0 577.545 577.545">
		<g>
			<path d="M245.531,245.532c4.893-4.896,11.42-7.589,18.375-7.589s13.482,2.696,18.375,7.589l49.734,49.734    c1.723,1.72,4.058,2.689,6.49,2.689s4.771-0.967,6.49-2.689l49.733-49.734c1.724-1.72,2.69-4.058,2.69-6.49    c0-2.433-0.967-4.771-2.69-6.49l-49.733-49.734c-21.668-21.662-50.469-33.589-81.093-33.589s-59.425,11.928-81.093,33.586    L33.602,332.022C11.934,353.69,0,382.494,0,413.128c0,30.637,11.934,59.432,33.605,81.084l49.731,49.73    c21.65,21.668,50.447,33.603,81.081,33.603s59.438-11.935,81.108-33.603l84.083-84.082c2.705-2.705,3.448-6.803,1.869-10.285    c-1.496-3.295-4.776-5.386-8.356-5.386c-0.205,0-0.407,0.007-0.615,0.021c-2.959,0.199-5.958,0.297-8.917,0.297    c-23.354,0-46.322-6.208-66.417-17.956c-1.444-0.844-3.042-1.254-4.629-1.254c-2.375,0-4.725,0.921-6.494,2.689l-53.238,53.238    c-4.902,4.901-11.426,7.604-18.372,7.604c-6.949,0-13.479-2.699-18.381-7.604l-49.734-49.734    c-4.908-4.896-7.61-11.411-7.616-18.348c-0.003-6.953,2.699-13.489,7.616-18.406L245.531,245.532z"/>
			<path d="M543.942,83.324L494.208,33.59C472.556,11.931,443.762,0,413.128,0s-59.438,11.928-81.105,33.587l-84.086,84.119    c-2.705,2.705-3.448,6.806-1.867,10.288c1.497,3.292,4.777,5.382,8.354,5.382c0.205,0,0.413-0.006,0.621-0.021    c2.987-0.202,6.013-0.303,9-0.303c23.4,0,46.316,6.206,66.274,17.947c1.45,0.854,3.057,1.267,4.65,1.267    c2.375,0,4.725-0.921,6.494-2.689l53.274-53.274c4.893-4.896,11.42-7.589,18.375-7.589s13.482,2.696,18.375,7.589l49.734,49.734    c10.123,10.135,10.123,26.634-0.003,36.775L332.017,332.014c-4.894,4.905-11.408,7.604-18.348,7.604    c-6.956,0-13.495-2.702-18.415-7.61l-49.723-49.725c-1.723-1.72-4.057-2.69-6.49-2.69c-2.433,0-4.771,0.967-6.49,2.69    l-49.734,49.734c-3.586,3.586-3.586,9.397,0,12.983l49.734,49.734c21.668,21.668,50.469,33.602,81.093,33.602    c30.625,0,59.426-11.934,81.094-33.602l149.205-149.206c21.668-21.658,33.603-50.462,33.603-81.102S565.61,104.983,543.942,83.324    z"/>
		</g>
	</svg>
	<ul class="tags__list">
	<li class="tags__item"><a class="tags__link btn" href="https://arxiv.org/abs/2310.04815" rel="tag">arXiv</a></li>
	<li class="tags__item"><a class="tags__link btn" href="https://www.luolc.com/publications/criticbench/#bibtex" rel="tag">bib</a></li>
</ul>
</div>
			<div class="pub__meta"><b>Liangchen Luo</b>, Zi Lin, Yinxiao Liu, Lei Shu, Yun Zhu, Jingbo Shang, Lei Meng.<br>
<em>arXiv preprint</em>.
2023.
			</div>
		</header><div class="content post__content clearfix">
			<h2 id="abstract">Abstract</h2>
<p>Critical thinking is essential for rational decision-making and problem-solving.
This skill hinges on the ability to provide precise and reasoned critiques and is a hallmark of human intelligence.
In the era of large language models (LLMs), this study explores the ability of LLMs to deliver accurate critiques across various tasks.
We are interested in this topic as a capable critic model could not only serve as a reliable evaluator, but also as a source of supervised signals for model tuning.
Particularly, if a model can self-critique, it has the potential for autonomous self-improvement.
To examine this, we introduce a unified evaluation framework for assessing the critique abilities of LLMs.
We develop a benchmark called CriticBench, which comprises 3K high-quality natural language queries and corresponding model responses; and annotate the correctness of these responses.
The benchmark cover tasks such as math problem-solving, code completion, and question answering.
We evaluate multiple LLMs on the collected dataset and our analysis reveals several noteworthy insights: (1) Critique is generally challenging for most LLMs, and this capability often emerges only when models are sufficiently large. (2) In particular, self-critique is especially difficult. Even top-performing LLMs struggle to achieve satisfactory performance. (3) Models tend to have lower critique accuracy on problems where they are most uncertain.
To this end, we introduce a simple yet effective baseline named self-check, which leverages self-critique to improve task performance for various models.
We hope this study serves as an initial exploration into understanding the critique abilities of LLMs, and aims to inform future research, including the development of more proficient critic models and the application of critiques across diverse tasks.</p>

		</div>








<h2 id="bibtex">BibTex</h2>
<pre><code>@article{Luo2023CriticBench,
  author = {Luo, Liangchen and Lin, Zi and Liu, Yinxiao and Shu, Lei and Zhu, Yun and Shang, Jingbo and Meng, Lei},
  title = {Critique Ability of Large Language Models},
  journal = {arXiv preprint arXiv:2310.04815},
  year = {2023}
}
</code></pre>
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/publications/query-modularized-detection/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Bridging the Gap Between Object Detection and User Intent via Query-Modulation</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/publications/rewritelm/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting</p></a>
	</div>
</nav>


			</section>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2015-2024 Liangchen Luo.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> based on <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>