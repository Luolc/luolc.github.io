<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Liangchen Luo</title>
    <link>https://www.luolc.com/</link>
    <description>Recent content on Liangchen Luo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 May 2024 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.luolc.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Work Experience</title>
      <link>https://www.luolc.com/news/google-deepmind/</link>
      <pubDate>Mon, 20 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/google-deepmind/</guid>
      <description>I transferred to Google DeepMind.</description>
    </item>
    
    <item>
      <title>Paper Accepted</title>
      <link>https://www.luolc.com/news/naacl-2024-accepted/</link>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/naacl-2024-accepted/</guid>
      <description>A paper got accepted to NAACL 2024.</description>
    </item>
    
    <item>
      <title>Paper Accepted</title>
      <link>https://www.luolc.com/news/aaai-2024-accepted/</link>
      <pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/aaai-2024-accepted/</guid>
      <description>A paper got accepted to AAAI 2024.</description>
    </item>
    
    <item>
      <title>Bridging the Gap Between Object Detection and User Intent via Query-Modulation</title>
      <link>https://www.luolc.com/publications/query-modularized-detection/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/query-modularized-detection/</guid>
      <description>Abstract When interacting with objects through cameras, or pictures, users often have a specific intent. For example, they may want to perform a visual search. With most object detection models relying on image pixels as their sole input, undesired results are not uncommon. Most typically: lack of a high-confidence detection on the object of interest, or detection with a wrong class label. The issue is especially severe when operating capacity-constrained mobile object detectors on-device.</description>
    </item>
    
    <item>
      <title>Large-Scale Generative Data-Free Distillation</title>
      <link>https://www.luolc.com/publications/data-free-distillation/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/data-free-distillation/</guid>
      <description>Abstract Knowledge distillation is one of the most popular and effective techniques for knowledge transfer, model compression and semi-supervised learning. Most existing distillation approaches require the access to original or augmented training samples. But this can be problematic in practice due to privacy, proprietary and availability concerns. Recent work has put forward some methods to tackle this problem, but they are either highly time-consuming or unable to scale to large datasets.</description>
    </item>
    
    <item>
      <title>Image segmentation via Cellular Automata</title>
      <link>https://www.luolc.com/publications/cellular-automata/</link>
      <pubDate>Tue, 11 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/cellular-automata/</guid>
      <description>Abstract In this paper, we propose a new approach for building cellular automata to solve real-world segmentation problems. We design and train a cellular automaton that can successfully segment high-resolution images. We consider a colony that densely inhabits the pixel grid, and all cells are governed by a randomized update that uses the current state, the color, and the state of the 3Ã—3 neighborhood. The space of possible rules is defined by a small neural network.</description>
    </item>
    
    <item>
      <title>MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning</title>
      <link>https://www.luolc.com/publications/parallel-multi-scale-attention/</link>
      <pubDate>Sun, 17 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/parallel-multi-scale-attention/</guid>
      <description>Abstract In sequence to sequence learning, the self-attention mechanism proves to be highly effective, and achieves significant improvements in many tasks. However, the self-attention mechanism is not without its own flaws. Although self-attention can model extremely long dependencies, the attention in deep layers tends to overconcentrate on a single token, leading to insufficient use of local information and difficultly in representing long sequences. In this work, we explore parallel multi-scale representation learning on sequence data, striving to capture both long-range and short-range language structures.</description>
    </item>
    
    <item>
      <title>Work Experience</title>
      <link>https://www.luolc.com/news/google-ai-resident/</link>
      <pubDate>Mon, 07 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/google-ai-resident/</guid>
      <description>I graduated from PKU and joined Google Research.</description>
    </item>
    
    <item>
      <title>Adaptive Gradient Methods with Dynamic Bound of Learning Rate</title>
      <link>https://www.luolc.com/publications/adabound/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/adabound/</guid>
      <description>Abstract Adaptive optimization methods such as AdaGrad, RMSProp and Adam have been proposed to achieve a rapid training process with an element-wise scaling term on learning rates. Though prevailing, they are observed to generalize poorly compared with Sgd or even fail to converge due to unstable and extreme learning rates. Recent work has put forward some algorithms such as AMSGrad to tackle this issue but they failed to achieve considerable improvement over existing methods.</description>
    </item>
    
    <item>
      <title>Learning Personalized End-to-End Goal-Oriented Dialog</title>
      <link>https://www.luolc.com/publications/personalized-goal-oriented-dialog/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/personalized-goal-oriented-dialog/</guid>
      <description>Abstract Most existing works on dialog systems only consider conversation content while neglecting the personality of the user the bot is interacting with, which begets several unsolved issues. In this paper, we present a personalized end-to-end model in an attempt to leverage personalization in goal-oriented dialogs. We first introduce a Profile Model which encodes user profiles into distributed embeddings and refers to conversation history from other similar users. Then a Preference Model captures user preferences over knowledge base entities to handle the ambiguity in user requests.</description>
    </item>
    
    <item>
      <title>Text Assisted Insight Ranking Using Context-Aware Memory Network</title>
      <link>https://www.luolc.com/publications/insight-ranking/</link>
      <pubDate>Wed, 30 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/insight-ranking/</guid>
      <description>Abstract Extracting valuable facts or informative summaries from multi-dimensional tables, i.e. insight mining, is an important task in data analysis and business intelligence. However, ranking the importance of insights remains a challenging and unexplored task. The main challenge is that explicitly scoring an insight or giving it a rank requires a thorough understanding of the tables and costs a lot of manual efforts, which leads to the lack of available training data for the insight ranking problem.</description>
    </item>
    
    <item>
      <title>Paper Accepted</title>
      <link>https://www.luolc.com/news/iclr-2019-accpeted/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/iclr-2019-accpeted/</guid>
      <description>A paper got accepted to ICLR 2019.</description>
    </item>
    
    <item>
      <title>An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation</title>
      <link>https://www.luolc.com/publications/auto-encoder-matching-dialog/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/publications/auto-encoder-matching-dialog/</guid>
      <description>Abstract Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The model contains two auto-encoders and one mapping module.</description>
    </item>
    
    <item>
      <title>Paper Accepted</title>
      <link>https://www.luolc.com/news/aaai-2019-accepted/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/aaai-2019-accepted/</guid>
      <description>Two papers got accepted to AAAI 2019.</description>
    </item>
    
    <item>
      <title>Award</title>
      <link>https://www.luolc.com/news/award-2018-liaokaiyuan/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/award-2018-liaokaiyuan/</guid>
      <description>I was awarded with Liao Kaiyuan Scholarship and Academic Excellence Award!</description>
    </item>
    
    <item>
      <title>Paper Accepted</title>
      <link>https://www.luolc.com/news/emnlp-2018-accepted/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/emnlp-2018-accepted/</guid>
      <description>A paper got accepted to EMNLP 2018.</description>
    </item>
    
    <item>
      <title>Internship</title>
      <link>https://www.luolc.com/news/didi-internship/</link>
      <pubDate>Thu, 26 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.luolc.com/news/didi-internship/</guid>
      <description>Started as a research assistant at DiDi AI Labs.</description>
    </item>
    
  </channel>
</rss>